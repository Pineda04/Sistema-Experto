# ğŸ¦™ Llama 3.1 â€” Interfaz Local

![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)
![Streamlit](https://img.shields.io/badge/Streamlit-Interfaz_Web-red)
![Ollama](https://img.shields.io/badge/Ollama-Llama_3.1-green)
![LangChain](https://img.shields.io/badge/LangChain-RAG-yellow)

**Sistema RAG** que emula el razonamiento de un **experto jurÃ­dico-normativo de la UNAH**.
Consulta documentos oficiales y recibe anÃ¡lisis estructurados, citas textuales, trazabilidad y recomendaciones prÃ¡cticas.

Ideal para estudiantes, docentes y personal administrativo que necesiten respuestas precisas sobre reglamentos, estatutos y procedimientos universitarios.

## CaracterÃ­sticas

- Emula el **razonamiento experto** con prompt maestro ultra-detallado
- AnÃ¡lisis estructurado en 6 secciones (AnÃ¡lisis preliminar â†’ Marco normativo â†’ Razonamiento â†’ Conclusiones â†’ RecomendaciÃ³n â†’ Certeza)
- Soporte para:
  - Consultas simples
  - AnÃ¡lisis de **casos complejos** con mÃºltiples variables
  - Casos de ejemplo predefinidos
- Interfaz web moderna con **Streamlit** (3 pestaÃ±as + descarga de informes)
- Modo consola incluido para pruebas rÃ¡pidas
- Base vectorial con **ChromaDB** + embeddings multilingÃ¼es optimizados
- RecuperaciÃ³n avanzada con **MMR** (mÃ¡xima relevancia + diversidad)
- Citas completas con pÃ¡gina y fragmento relevante

## Requisitos

Antes de instalar, asegÃºrate de tener:

- **Python 3.10+**
- **pip** actualizado
- **Ollama** instalado â†’ https://ollama.ai
- Modelo descargado:
  ```bash
  ollama pull llama3.1
  ```
- **Git** para clonar el repositorio

## ğŸ”§ InstalaciÃ³n

## 1ï¸âƒ£ Clonar el repositorio

```bash
git clone https://github.com/Pineda04/Sistema-Experto.git
```

## Entrar al proyecto

```bash
cd Sistema-Experto/
```

## Crear entorno virtual

### ğŸ”¹ Linux / macOS

```bash
python3 -m venv venv
source venv/bin/activate
```

### ğŸ”¹ Windows (CMD)

```cmd
python -m venv venv
venv\Scripts\activate
```

### ğŸ”¹ Windows (PowerShell)

```powershell
python -m venv venv
.\venv\Scripts\Activate.ps1
```

## ğŸ“¥ Instalar dependencias

```bash
pip install -r requirements.txt
```

Luego crea la carpeta "documentos y coloca tus documentos oficiales:

```bash
mkdir documentos
# pega aquÃ­ tus documentos
```

## â–¶ï¸ Ejecutar la aplicaciÃ³n

```bash
streamlit run app.py
# El anterior comando es para ejecutarla desde su interfaz
```

o tambiÃ©n se puede usar:

```bash
python test_console.py
# Este comando es par probar desde la terminal
```

---

## ğŸ§  Modelo utilizado

El archivo usa la variable:

```python
MODEL = "llama3.1"
```
Pero puede ser cambiada por cualquier otro modelo soportado por Ollama.

---

## ğŸ“ Estructura del proyecto
```
Sistema-Experto/
â”œâ”€â”€ app.py              â†’ Interfaz web con Streamlit
â”œâ”€â”€ rag_system.py       â†’ Clase principal RAGSystemUNAH
â”œâ”€â”€ test_console.py     â†’ Modo consola
â”œâ”€â”€ documentos/         â†’ Aqui van los documentos a usar
â”œâ”€â”€ chroma_db/          â†’ Base vectorial (se crea automÃ¡ticamente al ejecutar)
â”œâ”€â”€ requirements.txt    â†’ (librerias a instalar)
â”œâ”€â”€ README.md
â””â”€â”€ venv/               â†’ (creado localmente)
```